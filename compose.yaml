version: "3.7"

services:
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    user: "nobody:nobody"  # run as nobody user
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'  # save data for max 15 days
      # - '--storage.tsdb.retention.size=10GB' # size threshold for data retention if needed it
      # add new setup below for connect to loki/alloy
      - --web.enable-remote-write-receiver
    volumes:
      - ./prometheus.yaml:/etc/prometheus/prometheus.yml:ro
      - ./data/prometheus:/prometheus
      - ./alerts.yml:/etc/prometheus/alerts.yml:ro # alerts configuration

  grafana:
    image: grafana/grafana:12.1.1
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    environment:
    - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin} # you can change this or using ENV variable, but on default will using admin/admin
    - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin} # you can change this or using ENV variable, but on default will using admin/admin
    - GF_USERS_ALLOW_SIGN_UP=false
    - GF_LOG_MODE=console file  # Log to console and file
    - GF_LOG_LEVEL=info         # Log level
    - GF_PATHS_LOGS=/var/log/grafana  # Path log at container
    # add and download REDIS PLUGINS DATASOURCE if needed it 
    - GF_INSTALL_PLUGINS=redis-datasource
    volumes:
    - ./data/grafana:/var/lib/grafana
    - ./grafana/provisioning:/etc/grafana/provisioning
    - ./logs/grafana:/var/log/grafana # parsing grafana logs
    # if using redis on docker (because the connection will directly with redis not with prometheus), make sure to have same network with redis container (UNCOMMENT the networks below if needed it)
    # networks:
    #   - default
    #   - monitoring-db-network

  alertmanager:
    image: prom/alertmanager:v0.28.1
    container_name: alertmanager
    restart: unless-stopped
    ports:
      - "9093:9093"
    user: "65534:65534" # using user nobody:nobody
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/config.yml
      - ./logs/alertmanager:/alertmanager  # save log on folder host
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
      - '--log.level=debug'
  
  loki:
    image: grafana/loki:3.3.2
    container_name: loki
    restart: unless-stopped
    ports:
      - "3100:3100"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/local-config.yaml
      - ./data/loki:/loki
    networks:
      - default

  # testing alloy to replace promtail, alloy job here will be basically same for promtail, so you can choose which one will be user. For some information that promtail will be fully deprecated (and not supported at all) around after q1 2026
  # if using promtail before, you can use "promtail-to-alloy-config.sh" bash script for convert promtail config to alloy config.
  alloy:
    image: grafana/alloy:v1.9.1
    container_name: alloy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "alloy", "-version"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    volumes:
      - ./alloy/alloy-config.alloy:/etc/alloy/config.alloy
      - ./data/alloy_data:/var/lib/alloy/data  # Persistent storage for Alloy data
      - /var/log:/var/log:ro  # System logs
      - /:/rootfs:ro  # Root filesystem for logs
      - /run:/run:ro  # Run directory for logs
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker/:ro
      - /run/udev/data:/run/udev/data:ro
    command:
      - run 
      - --server.http.listen-addr=0.0.0.0:12345
      - --storage.path=/var/lib/alloy/data
      - /etc/alloy/config.alloy
    ports:
      - "12345:12345"  # Expose Alloy's HTTP server
    networks:
      - default
    depends_on:
      - loki

  blackbox_exporter:
    image: prom/blackbox-exporter:v0.27.0
    container_name: blackbox_exporter
    restart: unless-stopped
    ports:
      - "9115:9115"
    volumes:
      - ./blackbox_exporter/blackbox_exporter.yaml:/etc/blackbox_exporter/config.yml:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--spider", "http://localhost:9115/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default
    command:
      - --config.file=/etc/blackbox_exporter/config.yml
      - --web.listen-address=:9115
      - --log.level=info
    

  # Postgres Exporter, enable this if need to add monitoring to postgresql database and in this configuration, the postgresql database run on docker, so make sure the compose docker postgresql run on same Networks setup
  # postgres_exporter:
  #   image: quay.io/prometheuscommunity/postgres-exporter
  #   container_name: postgres_exporter
  #   restart: unless-stopped
  #   ports:
  #     - "9187:9187"
  #   environment:
  #     DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER}:${POSTGRES_PASS}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}?sslmode=disable"
  #   healthcheck:
  #     test: ["CMD", "wget", "--no-verbose", "--spider", "http://localhost:9187/metrics"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 10s
  #   networks:
  #     - default
  #     - monitoring-db-network

  # nginx prometheus exporter, enable this if need to add monitoring to nginx server
  # https://github.com/nginx/nginx-prometheus-exporter
  # make sure nginx server has enabled the stub status module and the endpoint is available at /nginx_status
  # https://docs.nginx.com/nginx/admin-guide/web-server/monitoring/web-server-metrics/
  # nginx_exporter:
  #   image: nginx/nginx-prometheus-exporter:1.4.2
  #   container_name: nginx_exporter
  #   restart: unless-stopped
  #   ports:
  #     - "9113:9113"
  #   command:
  #     - -nginx.scrape-uri=http://nginx/nginx_status
  #   healthcheck:
  #     test: ["CMD", "wget", "--no-verbose", "--spider", "http://localhost:9113/metrics"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 10s
  #   networks:
  #     - default
  #     - monitoring-db-network

# UNCOMENT the networks below if you need to use postgres exporter or nginx exporter, so they can access the postgres db or nginx server
# networks:
#   default:
#   # make sure if need to use postgres exporter to make sure if postgres using docker to using the same network below, so postgres_exporter can access the postgres db
#   monitoring-db-network:
#     external: true